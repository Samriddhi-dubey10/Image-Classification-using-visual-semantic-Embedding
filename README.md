# Image-Classification-using-visual-semantic-Embedding
In this project, a successful model has been developed that uses visual-semantic 
embedding to categorize the input image. The proposed model demonstrates that, even as 
test sample photos diverge more and more from those used in the training data set, the 
architecture is successful in using the semantic knowledge gathered by the linguistic 
model to generate precise estimations. Classification of images is in high demand and is 
mostly used in computer vision. The labels are generated dynamically from word 
embeddings in the descriptive text using visual semantics. The suggested model benefits 
from a wider variety of information to train from and increases in accuracy because it 
combines a visual model with a language model. As a result, the project's development 
began with a thorough literature review that covered every subject connected to image 
classification. The designed prototype also takes into consideration the detection of unseen 
images. i.e the model has not been trained with the image at all earlier
. Below in Table, all the outcomes of the project model are mentioned with its specifications.
![image](https://github.com/Samriddhi-dubey10/Image-Classification-using-visual-semantic-Embedding/assets/74581936/d3be1505-0604-4a86-ab30-468ff465d532)

Resnet 50 outcome

![image](https://github.com/Samriddhi-dubey10/Image-Classification-using-visual-semantic-Embedding/assets/74581936/aee86233-252e-4bd9-abda-5b538240aedd)

Vgg16 model outcome

![image](https://github.com/Samriddhi-dubey10/Image-Classification-using-visual-semantic-Embedding/assets/74581936/99cf21dc-3e61-4852-a4f4-deda06ee7688)

Vgg19 outcome
![image](https://github.com/Samriddhi-dubey10/Image-Classification-using-visual-semantic-Embedding/assets/74581936/587fd027-7f95-4de8-ba49-f63d7d40ef33)

